{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11815782,"sourceType":"datasetVersion","datasetId":7421468}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nfrom torch.utils.data import Dataset, DataLoader# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        # print(os.path.join(dirname, filename))\n        pass\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T11:23:29.311381Z","iopub.execute_input":"2025-05-20T11:23:29.312039Z","iopub.status.idle":"2025-05-20T11:23:34.760328Z","shell.execute_reply.started":"2025-05-20T11:23:29.312006Z","shell.execute_reply":"2025-05-20T11:23:34.759535Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\n# 1. Load the splits\ndef load_dakshina_splits(lang_code='hi', base_dir='dakshina_dataset_v1.0'):\n    lex_dir = f\"{base_dir}/{lang_code}/lexicons/\"\n    train_path = lex_dir + f\"{lang_code}.translit.sampled.train.tsv\"\n    dev_path   = lex_dir + f\"{lang_code}.translit.sampled.dev.tsv\"\n    test_path  = lex_dir + f\"{lang_code}.translit.sampled.test.tsv\"\n    train_df = pd.read_csv(train_path, sep='\\t', header=None, names=['native', 'latin', 'count'], na_filter = False)\n    dev_df   = pd.read_csv(dev_path,\n                           sep='\\t', header=None, names=['native', 'latin', 'count'], na_filter = False)\n    test_df  = pd.read_csv(test_path,  sep='\\t', header=None, names=['native', 'latin', 'count'], na_filter = False)\n    train_df.drop([\"count\"], axis = 1,inplace = True)\n    dev_df.drop([\"count\"], axis = 1,inplace = True)\n    test_df.drop([\"count\"], axis = 1,inplace = True)\n\n    return train_df, dev_df, test_df\n\n# 2. Preprocessing: add <start> and <end> tokens, tokenize as characters\ndef preprocess_df(df):\n    def process(text):\n        return ' '.join(['<start>'] + list(str(text).strip()) + ['<end>'])\n    df['native_proc'] = df['native'].apply(process)\n    df['latin_proc'] = df['latin'].apply(process)\n    return df\n\n# 3. Build vocabulary from training data only\ndef build_vocab(texts):\n    special_tokens = ['<pad>', '<unk>', '<start>', '<end>']\n    chars = set()\n    for text in texts:\n        chars.update(text.split())\n    chars = [c for c in sorted(chars) if c not in special_tokens]\n    vocab = special_tokens + chars\n    char2idx = {c: i for i, c in enumerate(vocab)}\n    idx2char = {i: c for i, c in enumerate(vocab)}\n    return char2idx, idx2char\n\n# 4. Convert text to padded sequences of indices\ndef texts_to_sequences(texts, vocab, max_len=None):\n    seqs = []\n    for text in texts:\n        seq = [vocab.get(c, vocab['<unk>']) for c in text.split()]\n        seqs.append(seq)\n    if not max_len:\n        max_len = max(len(seq) for seq in seqs)\n    padded_seqs = [seq + [vocab['<pad>']] * (max_len - len(seq)) for seq in seqs]\n    # print(padded_seqs , max_len)\n    return np.array(padded_seqs), max_len\n\n# 5. PyTorch Dataset\nclass TransliterationDataset(Dataset):\n    def __init__(self, src_seqs, trg_seqs):\n        self.src = torch.LongTensor(src_seqs)\n        self.trg = torch.LongTensor(trg_seqs)\n    def __len__(self):\n        return len(self.src)\n    def __getitem__(self, idx):\n        return {\n            'source': self.src[idx],\n            'target': self.trg[idx],\n            'target_input': self.trg[idx][:-1],  # Exclude <end>\n            'target_output': self.trg[idx][1:]   # Exclude <start>\n        }\n\n# 6. Main function to prepare everything\ndef prepare_dakshina_data(base_dir,lang_code='hi', batch_size=64):\n    # Load splits\n    train_df, dev_df, test_df = load_dakshina_splits(lang_code,base_dir)\n    train_df = preprocess_df(train_df)\n    dev_df = preprocess_df(dev_df)\n    test_df = preprocess_df(test_df)\n\n    # Build vocabs from training only\n    src_vocab, src_idx2char = build_vocab(train_df['latin_proc'])\n    trg_vocab, trg_idx2char = build_vocab(train_df['native_proc'])\n\n    # Find max lengths across all splits for consistent padding\n    src_max_len = max(\n        train_df['latin_proc'].apply(lambda x: len(x.split())).max(),\n        dev_df['latin_proc'].apply(lambda x: len(x.split())).max(),\n        test_df['latin_proc'].apply(lambda x: len(x.split())).max()\n    )\n    trg_max_len = max(\n        train_df['native_proc'].apply(lambda x: len(x.split())).max(),\n        dev_df['native_proc'].apply(lambda x: len(x.split())).max(),\n        test_df['native_proc'].apply(lambda x: len(x.split())).max()\n    )\n\n    # Convert to sequences\n    train_src, _ = texts_to_sequences(train_df['latin_proc'], src_vocab, src_max_len)\n    train_trg, _ = texts_to_sequences(train_df['native_proc'], trg_vocab, trg_max_len)\n    dev_src, _ = texts_to_sequences(dev_df['latin_proc'], src_vocab, src_max_len)\n    dev_trg, _ = texts_to_sequences(dev_df['native_proc'], trg_vocab, trg_max_len)\n    test_src, _ = texts_to_sequences(test_df['latin_proc'], src_vocab, src_max_len)\n    test_trg, _ = texts_to_sequences(test_df['native_proc'], trg_vocab, trg_max_len)\n\n    # Datasets and loaders\n    train_dataset = TransliterationDataset(train_src, train_trg)\n    dev_dataset = TransliterationDataset(dev_src, dev_trg)\n    test_dataset = TransliterationDataset(test_src, test_trg)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    dev_loader = DataLoader(dev_dataset, batch_size=batch_size)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n\n    return {\n        'train_loader': train_loader,\n        'dev_loader': dev_loader,\n        'test_loader': test_loader,\n        'src_vocab': src_vocab,\n        'trg_vocab': trg_vocab,\n        'src_idx2char': src_idx2char,\n        'trg_idx2char': trg_idx2char,\n        'src_max_len': src_max_len,\n        'trg_max_len': trg_max_len,\n    }\n\n# Example usage\nPATH = \"/kaggle/input/dakshina/dakshina_dataset_v1.0/\"\ndata = prepare_dakshina_data(lang_code='hi', batch_size=64,base_dir = PATH)\nprint(f\"Source vocab size: {len(data['src_vocab'])}\")\nprint(f\"Target vocab size: {len(data['trg_vocab'])}\")\nprint(f\"Train batches: {len(data['train_loader'])}\")\nprint(f\"Dev batches: {len(data['dev_loader'])}\")\nprint(f\"Test batches: {len(data['test_loader'])}\")\n\n# Check a batch\nbatch = next(iter(data['train_loader']))\nprint(\"Source batch shape:\", batch['source'].shape)\nprint(\"Target input batch shape:\", batch['target_input'].shape)\nprint(\"Target output batch shape:\", batch['target_output'].shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T11:23:34.761472Z","iopub.execute_input":"2025-05-20T11:23:34.761806Z","iopub.status.idle":"2025-05-20T11:23:35.818992Z","shell.execute_reply.started":"2025-05-20T11:23:34.761778Z","shell.execute_reply":"2025-05-20T11:23:35.818109Z"}},"outputs":[{"name":"stdout","text":"Source vocab size: 30\nTarget vocab size: 67\nTrain batches: 691\nDev batches: 69\nTest batches: 71\nSource batch shape: torch.Size([64, 22])\nTarget input batch shape: torch.Size([64, 20])\nTarget output batch shape: torch.Size([64, 20])\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport wandb\nfrom tqdm import tqdm\nimport numpy as np\n\nclass Seq2Seq(nn.Module):\n    def __init__(self, src_vocab_size, trg_vocab_size, \n                 embed_dim=256, hidden_size=512,\n                 enc_layers=2, dec_layers=2,\n                 cell_type='lstm', dropout=0.3):\n        super().__init__()\n        \n        self.src_vocab_size = src_vocab_size\n        self.trg_vocab_size = trg_vocab_size\n        self.hidden_size = hidden_size\n        self.cell_type = cell_type.lower()\n        self.enc_layers = enc_layers\n        self.dec_layers = dec_layers\n\n        # Embedding layers\n        self.src_embed = nn.Embedding(src_vocab_size, embed_dim)\n        self.trg_embed = nn.Embedding(trg_vocab_size, embed_dim)\n        \n        # RNN cell selection and initialization\n        rnn_dict = {\n            'rnn': nn.RNN,\n            'lstm': nn.LSTM,\n            'gru': nn.GRU\n        }\n        rnn_class = rnn_dict[self.cell_type]\n        \n        # Encoder\n        self.encoder = rnn_class(\n            embed_dim, hidden_size, enc_layers,\n            dropout=dropout if enc_layers > 1 else 0,\n            batch_first=True\n        )\n        \n        # Decoder \n        self.decoder = rnn_class(\n            embed_dim, hidden_size, dec_layers,\n            dropout=dropout if dec_layers > 1 else 0,\n            batch_first=True\n        )\n        \n        # Final projection layer\n        self.fc = nn.Linear(hidden_size, trg_vocab_size)\n        \n    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n        batch_size = src.size(0)\n        trg_len = trg.size(1)\n        \n        # Encoder forward\n        src_embedded = self.src_embed(src)\n        encoder_outputs, hidden = self._run_encoder(src_embedded)\n        \n        # Adjust hidden states for decoder\n        if self.cell_type == 'lstm':\n            hidden = self._adapt_hidden(hidden, self.dec_layers)\n        else:\n            if self.enc_layers > 1:  # Handle multi-layer RNN/GRU encoder\n                hidden = hidden[-self.dec_layers:]\n            else:  # Single-layer encoder → expand for multi-layer decoder\n                hidden = hidden.repeat(self.dec_layers, 1, 1)\n        \n        # Decoder initialization\n        inputs = trg[:, 0]\n        outputs = torch.zeros(batch_size, trg_len, self.trg_vocab_size).to(src.device)\n        \n        # Decoder steps\n        for t in range(1, trg_len):\n            trg_embedded = self.trg_embed(inputs).unsqueeze(1)\n            \n            if self.cell_type == 'lstm':\n                out, (hidden, cell) = self.decoder(trg_embedded, hidden)\n                hidden = (hidden, cell)\n            else:\n                out, hidden = self.decoder(trg_embedded, hidden)\n            \n            output = self.fc(out.squeeze(1))\n            outputs[:, t] = output\n            \n            # Teacher forcing\n            use_teacher = torch.rand(1).item() < teacher_forcing_ratio\n            top1 = output.argmax(1)\n            inputs = trg[:, t] if use_teacher else top1\n            \n        return outputs\n\n\n    def _adapt_hidden(self, hidden, target_layers):\n        \"\"\"Adjust hidden states to match target layer count\"\"\"\n        if isinstance(hidden, tuple):  # LSTM case\n            return (hidden[0][-target_layers:], \n                    hidden[1][-target_layers:])\n        else:  # RNN/GRU case\n            return hidden[-target_layers:]\n\n    \n    def _run_encoder(self, src_embedded):\n        if self.cell_type == 'lstm':\n            outputs, (hidden, cell) = self.encoder(src_embedded)\n            return outputs, (hidden, cell)\n        else:\n            outputs, hidden = self.encoder(src_embedded)\n            return outputs, hidden\n    \n    def _decoder_step(self, inputs, hidden):\n        trg_embedded = self.trg_embed(inputs).unsqueeze(1)\n        \n        if self.cell_type == 'lstm':\n            hidden, cell = hidden\n            out, (hidden, cell) = self.decoder(trg_embedded, (hidden, cell))\n            hidden_state = (hidden, cell)\n        else:\n            out, hidden = self.decoder(trg_embedded, hidden)\n            hidden_state = hidden\n            \n        output = self.fc(out.squeeze(1))\n        return output, hidden_state\n    \n    def beam_search_decode(self, src, beam_width=3, max_len=20):\n        self.eval()\n        with torch.no_grad():\n            src_embedded = self.src_embed(src)\n            encoder_outputs, hidden = self._run_encoder(src_embedded)\n            \n            # Initialize beam\n            start_token = self.trg_embed.weight.shape[0] - 4  # <start> index\n            beams = [([start_token], 0, hidden)]\n            \n            for _ in range(max_len):\n                candidates = []\n                for seq, score, hidden_state in beams:\n                    if seq[-1] == self.trg_embed.weight.shape[0] - 3:  # <end>\n                        candidates.append((seq, score, hidden_state))\n                        continue\n                        \n                    inputs = torch.LongTensor([seq[-1]]).to(src.device)\n                    output, new_hidden = self._decoder_step(inputs, hidden_state)\n                    topk_probs, topk_ids = torch.topk(torch.log_softmax(output, dim=1), beam_width)\n                    \n                    for i in range(beam_width):\n                        candidates.append((\n                            seq + [topk_ids[0, i].item()],\n                            score + topk_probs[0, i].item(),\n                            new_hidden\n                        ))\n                \n                # Keep top-k candidates\n                candidates.sort(key=lambda x: x[1]/len(x[0]), reverse=True)\n                beams = candidates[:beam_width]\n                \n                # Check if all beams end with <end>\n                if all([seq[-1] == self.trg_embed.weight.shape[0] - 3 for seq, _, _ in beams]):\n                    break\n                    \n            # Return best sequence (strip <start> and <end>)\n            best_seq = beams[0][0][1:-1]\n            return torch.LongTensor(best_seq).unsqueeze(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T11:23:35.820197Z","iopub.execute_input":"2025-05-20T11:23:35.820425Z","iopub.status.idle":"2025-05-20T11:23:38.356908Z","shell.execute_reply.started":"2025-05-20T11:23:35.820409Z","shell.execute_reply":"2025-05-20T11:23:38.356180Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def train(config=None):\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    # with wandb.init(config=config):\n    # config = wandb.config\n    pad_idx = data['trg_vocab']['<pad>']\n    \n    # Model initialization\n    model = Seq2Seq(\n        src_vocab_size=len(data['src_vocab']),\n        trg_vocab_size=len(data['trg_vocab']),\n        # embed_dim=config.embed_dim,\n        # hidden_size=config.hidden_size,\n        # enc_layers=config.enc_layers,\n        # dec_layers=config.dec_layers,\n        # cell_type=config.cell_type,\n        # dropout=config.dropout\n    ).to(device)\n    \n    # Training setup\n    # optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n    optimizer = optim.Adam(model.parameters(), lr=0.0005)\n    criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n    best_val_loss = float('inf')\n    \n    for epoch in range(10):\n        # Training\n        model.train()\n        train_loss = 0\n        for batch in tqdm(data['train_loader'], desc=f\"Epoch {epoch+1}\"):\n            src = batch['source'].to(device)\n            trg = batch['target'].to(device)\n            \n            optimizer.zero_grad()\n            output = model(src, trg, teacher_forcing_ratio=0.5)\n            \n            # Reshape for loss calculation\n            output = output[:, 1:].reshape(-1, output.size(-1))\n            targets = batch['target_output'].to(device).reshape(-1)\n            \n            loss = criterion(output, targets)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n            \n            train_loss += loss.item()\n        \n        # Validation\n        model.eval()\n        val_loss = 0\n        correct = 0\n        total = 0\n        \n        with torch.no_grad():\n            for batch in data['dev_loader']:\n                src = batch['source'].to(device)\n                trg = batch['target'].to(device)\n                \n                output = model(src, trg, teacher_forcing_ratio=0)\n                output = output[:, 1:].reshape(-1, output.size(-1))\n                targets = batch['target_output'].to(device).reshape(-1)\n                \n                loss = criterion(output, targets)\n                val_loss += loss.item()\n                \n                # Calculate accuracy\n                _, predicted = torch.max(output, 1)\n                mask = targets != pad_idx\n                correct += ((predicted == targets) * mask).sum().item()\n                total += mask.sum().item()\n        \n        avg_train_loss = train_loss / len(data['train_loader'])\n        avg_val_loss = val_loss / len(data['dev_loader'])\n        val_acc = correct / total\n        \n        # wandb.log({\n        #     \"epoch\": epoch,\n        #     \"train_loss\": avg_train_loss,\n        #     \"val_loss\": avg_val_loss,\n        #     \"val_acc\": val_acc\n        # })\n        print( \"epoch:\", epoch,\n            \"train_loss:\", avg_train_loss,\n            \"val_loss:\", avg_val_loss,\n            \"val_acc:\", val_acc)\n        \n        # Save best model\n        if avg_val_loss < best_val_loss:\n            best_val_loss = avg_val_loss\n            torch.save(model.state_dict(), \"best_model.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T11:23:38.902890Z","iopub.execute_input":"2025-05-20T11:23:38.903354Z","iopub.status.idle":"2025-05-20T11:23:38.913249Z","shell.execute_reply.started":"2025-05-20T11:23:38.903329Z","shell.execute_reply":"2025-05-20T11:23:38.912517Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T07:10:55.751733Z","iopub.execute_input":"2025-05-20T07:10:55.751995Z","iopub.status.idle":"2025-05-20T07:15:55.322767Z","shell.execute_reply.started":"2025-05-20T07:10:55.751975Z","shell.execute_reply":"2025-05-20T07:15:55.322174Z"}},"outputs":[{"name":"stderr","text":"Epoch 1: 100%|██████████| 691/691 [00:29<00:00, 23.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 0 train_loss: 2.4701947839836307 val_loss: 1.6738811765891919 val_acc: 0.49993402823591504\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 691/691 [00:28<00:00, 24.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 1 train_loss: 1.0600401615095898 val_loss: 1.2050387842067773 val_acc: 0.6462264150943396\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 691/691 [00:28<00:00, 24.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 2 train_loss: 0.7334234876242802 val_loss: 1.0748567460239797 val_acc: 0.6862712758939175\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 691/691 [00:28<00:00, 24.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 3 train_loss: 0.5758513196677444 val_loss: 1.0228825133779775 val_acc: 0.7068544662884285\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 691/691 [00:28<00:00, 24.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 4 train_loss: 0.4763692596283042 val_loss: 1.0337142952974292 val_acc: 0.7120332497690989\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|██████████| 691/691 [00:28<00:00, 24.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 5 train_loss: 0.3988922502516665 val_loss: 1.0324933671432992 val_acc: 0.72107138144874\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7: 100%|██████████| 691/691 [00:28<00:00, 24.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 6 train_loss: 0.3296491702110136 val_loss: 1.0404761606368467 val_acc: 0.7294168096054888\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8: 100%|██████████| 691/691 [00:28<00:00, 23.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 7 train_loss: 0.2856514769378516 val_loss: 1.112315789512966 val_acc: 0.7242710120068611\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9: 100%|██████████| 691/691 [00:28<00:00, 24.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 8 train_loss: 0.24038467816092 val_loss: 1.1648674866427546 val_acc: 0.7170471038395567\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10: 100%|██████████| 691/691 [00:28<00:00, 24.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 9 train_loss: 0.2091788559311033 val_loss: 1.172158757413643 val_acc: 0.7247328143554559\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"def test_model_and_save_predictions(model, test_loader, \n                                  src_vocab, src_idx2char,\n                                  trg_vocab, trg_idx2char, \n                                  filename='vanilla_prediction.tsv'):\n    model.eval()\n    correct = 0\n    total = 0\n    pad_idx = trg_vocab['<pad>']\n    device = next(model.parameters()).device\n    \n    inputs_list = []\n    predictions_list = []\n    targets_list = []\n\n    with torch.no_grad():\n        for batch in test_loader:\n            src = batch['source'].to(device)\n            trg = batch['target'].to(device)\n            \n            # Greedy decoding\n            outputs = model(src, trg, teacher_forcing_ratio=0)\n            outputs_reshaped = outputs[:, 1:].reshape(-1, outputs.size(-1))\n            targets = batch['target_output'].to(device).reshape(-1)\n            \n            _, predicted = torch.max(outputs_reshaped, 1)\n            mask = targets != pad_idx\n            correct += ((predicted == targets) * mask).sum().item()\n            total += mask.sum().item()\n            \n            # Convert indices to strings\n            for i in range(src.size(0)):\n                # Decode SOURCE (Latin) using source vocab\n                src_seq = src[i].cpu().tolist()\n                src_chars = [src_idx2char[idx] for idx in src_seq \n                           if idx not in [src_vocab['<start>'], src_vocab['<end>'], src_vocab['<pad>']]]\n                latin_input = ''.join(src_chars)\n                \n                # Decode PREDICTION (Devanagari) using target vocab\n                pred_seq = outputs[i].argmax(dim=1).cpu().tolist()\n                pred_chars = [trg_idx2char[idx] for idx in pred_seq \n                            if idx not in [trg_vocab['<start>'], trg_vocab['<end>'], trg_vocab['<pad>']]]\n                devanagari_pred = ''.join(pred_chars)\n                \n                # Decode TARGET (Devanagari) using target vocab\n                trg_seq = trg[i].cpu().tolist()\n                trg_chars = [trg_idx2char[idx] for idx in trg_seq \n                           if idx not in [trg_vocab['<start>'], trg_vocab['<end>'], trg_vocab['<pad>']]]\n                devanagari_target = ''.join(trg_chars)\n                \n                inputs_list.append(latin_input)\n                predictions_list.append(devanagari_pred)\n                targets_list.append(devanagari_target)\n    \n    # Save to TSV\n    import pandas as pd\n    df = pd.DataFrame({\n        'latin_input': inputs_list,\n        'devanagari_prediction': predictions_list,\n        'devanagari_target': targets_list\n    })\n    df.to_csv(filename, sep='\\t', index=False, encoding='utf-8')\n    \n    return correct / total\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nbest_model = Seq2Seq(\n    len(data['src_vocab']),\n    len(data['trg_vocab']),\n    embed_dim=256,  # Replace with best params from sweep\n    hidden_size=512\n).to(device)\nbest_model.load_state_dict(torch.load(\"best_model.pth\"))\n\n# Usage\ntest_acc = test_model_and_save_predictions(\n    best_model, \n    data['test_loader'],\n    data['src_vocab'],  # Source vocab (Latin)\n    data['src_idx2char'],\n    data['trg_vocab'],  # Target vocab (Devanagari)\n    data['trg_idx2char'],\n    'vanilla_prediction.tsv'\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T11:24:36.773026Z","iopub.execute_input":"2025-05-20T11:24:36.773684Z","iopub.status.idle":"2025-05-20T11:24:38.899383Z","shell.execute_reply.started":"2025-05-20T11:24:36.773648Z","shell.execute_reply":"2025-05-20T11:24:38.898596Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"print(f\"Test Accuracy: {test_acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T11:24:38.900413Z","iopub.execute_input":"2025-05-20T11:24:38.900743Z","iopub.status.idle":"2025-05-20T11:24:38.904677Z","shell.execute_reply.started":"2025-05-20T11:24:38.900724Z","shell.execute_reply":"2025-05-20T11:24:38.903976Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 0.7126\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"pred = pd.read_csv(\"/kaggle/working/vanilla_prediction.tsv\" , sep = '\\t')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T11:24:40.990335Z","iopub.execute_input":"2025-05-20T11:24:40.990621Z","iopub.status.idle":"2025-05-20T11:24:41.003078Z","shell.execute_reply.started":"2025-05-20T11:24:40.990597Z","shell.execute_reply":"2025-05-20T11:24:41.002444Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"pred.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T11:25:09.353702Z","iopub.execute_input":"2025-05-20T11:25:09.354377Z","iopub.status.idle":"2025-05-20T11:25:09.359226Z","shell.execute_reply.started":"2025-05-20T11:25:09.354351Z","shell.execute_reply":"2025-05-20T11:25:09.358628Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(4502, 3)"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"correct_pred = pred[pred[\"devanagari_prediction\"] == pred[\"devanagari_target\"]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T11:25:10.722394Z","iopub.execute_input":"2025-05-20T11:25:10.722928Z","iopub.status.idle":"2025-05-20T11:25:10.728113Z","shell.execute_reply.started":"2025-05-20T11:25:10.722905Z","shell.execute_reply":"2025-05-20T11:25:10.727489Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"correct_pred.shape[0]/pred.shape[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T11:25:12.198032Z","iopub.execute_input":"2025-05-20T11:25:12.198743Z","iopub.status.idle":"2025-05-20T11:25:12.203407Z","shell.execute_reply.started":"2025-05-20T11:25:12.198719Z","shell.execute_reply":"2025-05-20T11:25:12.202524Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"0.3427365615282097"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T11:23:03.903365Z","iopub.execute_input":"2025-05-20T11:23:03.904074Z","iopub.status.idle":"2025-05-20T11:23:03.911875Z","shell.execute_reply.started":"2025-05-20T11:23:03.904045Z","shell.execute_reply":"2025-05-20T11:23:03.911236Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"top_matches = correct_pred.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T08:21:11.491986Z","iopub.execute_input":"2025-05-20T08:21:11.492255Z","iopub.status.idle":"2025-05-20T08:21:11.496081Z","shell.execute_reply.started":"2025-05-20T08:21:11.492234Z","shell.execute_reply":"2025-05-20T08:21:11.495445Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"top_matches = pd.concat([top_matches,correct_pred.iloc[500:505]] , axis = 0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T08:21:15.085372Z","iopub.execute_input":"2025-05-20T08:21:15.086026Z","iopub.status.idle":"2025-05-20T08:21:15.090140Z","shell.execute_reply.started":"2025-05-20T08:21:15.086003Z","shell.execute_reply":"2025-05-20T08:21:15.089336Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"top_matches = pd.concat([top_matches,correct_pred.iloc[1000:1005]] , axis = 0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T08:21:19.536245Z","iopub.execute_input":"2025-05-20T08:21:19.536500Z","iopub.status.idle":"2025-05-20T08:21:19.541402Z","shell.execute_reply.started":"2025-05-20T08:21:19.536480Z","shell.execute_reply":"2025-05-20T08:21:19.540593Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"top_matches = pd.concat([top_matches,correct_pred.tail()] , axis = 0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T08:21:22.398666Z","iopub.execute_input":"2025-05-20T08:21:22.398926Z","iopub.status.idle":"2025-05-20T08:21:22.403288Z","shell.execute_reply.started":"2025-05-20T08:21:22.398904Z","shell.execute_reply":"2025-05-20T08:21:22.402512Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"top_matches.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T08:21:23.273693Z","iopub.execute_input":"2025-05-20T08:21:23.273913Z","iopub.status.idle":"2025-05-20T08:21:23.278730Z","shell.execute_reply.started":"2025-05-20T08:21:23.273898Z","shell.execute_reply":"2025-05-20T08:21:23.278084Z"}},"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"(20, 3)"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"top_matches","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T08:21:24.493979Z","iopub.execute_input":"2025-05-20T08:21:24.494461Z","iopub.status.idle":"2025-05-20T08:21:24.502045Z","shell.execute_reply.started":"2025-05-20T08:21:24.494440Z","shell.execute_reply":"2025-05-20T08:21:24.501350Z"}},"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"     latin_input devanagari_prediction devanagari_target\n0            ank                   अंक               अंक\n8       angaarak                अंगारक            अंगारक\n20         andha                  अंधा              अंधा\n21      andhapan                अंधापन            अंधापन\n22       andheri                अंधेरी            अंधेरी\n1596         dvc                डीवीसी            डीवीसी\n1624     domenic               डोमेनिक           डोमेनिक\n1626      dolane                 डोलने             डोलने\n1627       dolne                 डोलने             डोलने\n1633      drager                ड्रेजर            ड्रेजर\n2916      byavar                ब्यावर            ब्यावर\n2920   brahmleen             ब्रह्मलीन         ब्रह्मलीन\n2922       bravo                ब्रावो            ब्रावो\n2930        brok                 ब्रोक             ब्रोक\n2931       broke                 ब्रोक             ब्रोक\n4484     hemwati                हेमवती            हेमवती\n4485        help                 हेल्प             हेल्प\n4486      helper                हेल्पर            हेल्पर\n4487       haito                  हैतो              हैतो\n4488      hairam                  हैरम              हैरम","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>latin_input</th>\n      <th>devanagari_prediction</th>\n      <th>devanagari_target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ank</td>\n      <td>अंक</td>\n      <td>अंक</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>angaarak</td>\n      <td>अंगारक</td>\n      <td>अंगारक</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>andha</td>\n      <td>अंधा</td>\n      <td>अंधा</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>andhapan</td>\n      <td>अंधापन</td>\n      <td>अंधापन</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>andheri</td>\n      <td>अंधेरी</td>\n      <td>अंधेरी</td>\n    </tr>\n    <tr>\n      <th>1596</th>\n      <td>dvc</td>\n      <td>डीवीसी</td>\n      <td>डीवीसी</td>\n    </tr>\n    <tr>\n      <th>1624</th>\n      <td>domenic</td>\n      <td>डोमेनिक</td>\n      <td>डोमेनिक</td>\n    </tr>\n    <tr>\n      <th>1626</th>\n      <td>dolane</td>\n      <td>डोलने</td>\n      <td>डोलने</td>\n    </tr>\n    <tr>\n      <th>1627</th>\n      <td>dolne</td>\n      <td>डोलने</td>\n      <td>डोलने</td>\n    </tr>\n    <tr>\n      <th>1633</th>\n      <td>drager</td>\n      <td>ड्रेजर</td>\n      <td>ड्रेजर</td>\n    </tr>\n    <tr>\n      <th>2916</th>\n      <td>byavar</td>\n      <td>ब्यावर</td>\n      <td>ब्यावर</td>\n    </tr>\n    <tr>\n      <th>2920</th>\n      <td>brahmleen</td>\n      <td>ब्रह्मलीन</td>\n      <td>ब्रह्मलीन</td>\n    </tr>\n    <tr>\n      <th>2922</th>\n      <td>bravo</td>\n      <td>ब्रावो</td>\n      <td>ब्रावो</td>\n    </tr>\n    <tr>\n      <th>2930</th>\n      <td>brok</td>\n      <td>ब्रोक</td>\n      <td>ब्रोक</td>\n    </tr>\n    <tr>\n      <th>2931</th>\n      <td>broke</td>\n      <td>ब्रोक</td>\n      <td>ब्रोक</td>\n    </tr>\n    <tr>\n      <th>4484</th>\n      <td>hemwati</td>\n      <td>हेमवती</td>\n      <td>हेमवती</td>\n    </tr>\n    <tr>\n      <th>4485</th>\n      <td>help</td>\n      <td>हेल्प</td>\n      <td>हेल्प</td>\n    </tr>\n    <tr>\n      <th>4486</th>\n      <td>helper</td>\n      <td>हेल्पर</td>\n      <td>हेल्पर</td>\n    </tr>\n    <tr>\n      <th>4487</th>\n      <td>haito</td>\n      <td>हैतो</td>\n      <td>हैतो</td>\n    </tr>\n    <tr>\n      <th>4488</th>\n      <td>hairam</td>\n      <td>हैरम</td>\n      <td>हैरम</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":51},{"cell_type":"code","source":"pred.tail(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T08:15:01.864958Z","iopub.execute_input":"2025-05-20T08:15:01.865531Z","iopub.status.idle":"2025-05-20T08:15:01.873352Z","shell.execute_reply.started":"2025-05-20T08:15:01.865506Z","shell.execute_reply":"2025-05-20T08:15:01.872543Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"       latin_input devanagari_prediction devanagari_target\n4492          have                   हवे               हैव\n4493          hong                  होंग             हॉन्ग\n4494          half                  हल्फ               हॉफ\n4495          hoaf                   होफ               हॉफ\n4496        hounga                 हौंगा            होऊंगा\n4497       holding              हॉल्डिंग          होल्डिंग\n4498  hoshangabaad             होषंगाबाद         होशंगाबाद\n4499   hoshangabad             होषंगाबाद         होशंगाबाद\n4500        hostes               हॉस्ट्स           होस्टेस\n4501       hostess              हॉस्टेसस           होस्टेस","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>latin_input</th>\n      <th>devanagari_prediction</th>\n      <th>devanagari_target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4492</th>\n      <td>have</td>\n      <td>हवे</td>\n      <td>हैव</td>\n    </tr>\n    <tr>\n      <th>4493</th>\n      <td>hong</td>\n      <td>होंग</td>\n      <td>हॉन्ग</td>\n    </tr>\n    <tr>\n      <th>4494</th>\n      <td>half</td>\n      <td>हल्फ</td>\n      <td>हॉफ</td>\n    </tr>\n    <tr>\n      <th>4495</th>\n      <td>hoaf</td>\n      <td>होफ</td>\n      <td>हॉफ</td>\n    </tr>\n    <tr>\n      <th>4496</th>\n      <td>hounga</td>\n      <td>हौंगा</td>\n      <td>होऊंगा</td>\n    </tr>\n    <tr>\n      <th>4497</th>\n      <td>holding</td>\n      <td>हॉल्डिंग</td>\n      <td>होल्डिंग</td>\n    </tr>\n    <tr>\n      <th>4498</th>\n      <td>hoshangabaad</td>\n      <td>होषंगाबाद</td>\n      <td>होशंगाबाद</td>\n    </tr>\n    <tr>\n      <th>4499</th>\n      <td>hoshangabad</td>\n      <td>होषंगाबाद</td>\n      <td>होशंगाबाद</td>\n    </tr>\n    <tr>\n      <th>4500</th>\n      <td>hostes</td>\n      <td>हॉस्ट्स</td>\n      <td>होस्टेस</td>\n    </tr>\n    <tr>\n      <th>4501</th>\n      <td>hostess</td>\n      <td>हॉस्टेसस</td>\n      <td>होस्टेस</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"dl3wandb\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T08:25:59.642311Z","iopub.execute_input":"2025-05-20T08:25:59.642588Z","iopub.status.idle":"2025-05-20T08:25:59.791827Z","shell.execute_reply.started":"2025-05-20T08:25:59.642567Z","shell.execute_reply":"2025-05-20T08:25:59.791296Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"wandb.login(key =secret_value_0 )\nwandb.init(project=\"DA6401_assignment3\", name=\"devanagari_match_log\")\ntable = wandb.Table(columns=[\"latin_input\",\"devanagari_prediction\", \"devanagari_target\"])\nfor _, row in top_matches.iterrows():\n    table.add_data(row[\"latin_input\"],row[\"devanagari_prediction\"], row[\"devanagari_target\"])\n\n# Step 6: Log the table\nwandb.log({\"Sample Matches\": table})\n\n# Finish the run\nwandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T08:26:03.546173Z","iopub.execute_input":"2025-05-20T08:26:03.546787Z","iopub.status.idle":"2025-05-20T08:26:18.441008Z","shell.execute_reply.started":"2025-05-20T08:26:03.546765Z","shell.execute_reply":"2025-05-20T08:26:18.440472Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mda24s021\u001b[0m (\u001b[33mda24s021-indian-institute-of-technology-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_082610-fdnyu0ew</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24s021-indian-institute-of-technology-madras/DA6401_assignment3/runs/fdnyu0ew' target=\"_blank\">devanagari_match_log</a></strong> to <a href='https://wandb.ai/da24s021-indian-institute-of-technology-madras/DA6401_assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24s021-indian-institute-of-technology-madras/DA6401_assignment3' target=\"_blank\">https://wandb.ai/da24s021-indian-institute-of-technology-madras/DA6401_assignment3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24s021-indian-institute-of-technology-madras/DA6401_assignment3/runs/fdnyu0ew' target=\"_blank\">https://wandb.ai/da24s021-indian-institute-of-technology-madras/DA6401_assignment3/runs/fdnyu0ew</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">devanagari_match_log</strong> at: <a href='https://wandb.ai/da24s021-indian-institute-of-technology-madras/DA6401_assignment3/runs/fdnyu0ew' target=\"_blank\">https://wandb.ai/da24s021-indian-institute-of-technology-madras/DA6401_assignment3/runs/fdnyu0ew</a><br> View project at: <a href='https://wandb.ai/da24s021-indian-institute-of-technology-madras/DA6401_assignment3' target=\"_blank\">https://wandb.ai/da24s021-indian-institute-of-technology-madras/DA6401_assignment3</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250520_082610-fdnyu0ew/logs</code>"},"metadata":{}}],"execution_count":53},{"cell_type":"code","source":"def train(config=None):\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    with wandb.init(config=config):\n        config = wandb.config\n        pad_idx = data['trg_vocab']['<pad>']\n        \n        # Model initialization\n        model = Seq2Seq(\n            src_vocab_size=len(data['src_vocab']),\n            trg_vocab_size=len(data['trg_vocab']),\n            embed_dim=config.embed_dim,\n            hidden_size=config.hidden_size,\n            enc_layers=config.enc_layers,\n            dec_layers=config.dec_layers,\n            cell_type=config.cell_type,\n            dropout=config.dropout\n        ).to(device)\n        \n        # Training setup\n        optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n        criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n        best_val_loss = float('inf')\n        \n        for epoch in range(config.epochs):\n            # Training\n            model.train()\n            train_loss = 0\n            for batch in tqdm(data['train_loader'], desc=f\"Epoch {epoch+1}\"):\n                src = batch['source'].to(device)\n                trg = batch['target'].to(device)\n                \n                optimizer.zero_grad()\n                output = model(src, trg, teacher_forcing_ratio=config.teacher_forcing)\n                \n                # Reshape for loss calculation\n                output = output[:, 1:].reshape(-1, output.size(-1))\n                targets = batch['target_output'].to(device).reshape(-1)\n                \n                loss = criterion(output, targets)\n                loss.backward()\n                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n                optimizer.step()\n                \n                train_loss += loss.item()\n            \n            # Validation\n            model.eval()\n            val_loss = 0\n            correct = 0\n            total = 0\n            \n            with torch.no_grad():\n                for batch in data['dev_loader']:\n                    src = batch['source'].to(device)\n                    trg = batch['target'].to(device)\n                    \n                    output = model(src, trg, teacher_forcing_ratio=0)\n                    output = output[:, 1:].reshape(-1, output.size(-1))\n                    targets = batch['target_output'].to(device).reshape(-1)\n                    \n                    loss = criterion(output, targets)\n                    val_loss += loss.item()\n                    \n                    # Calculate accuracy\n                    _, predicted = torch.max(output, 1)\n                    mask = targets != pad_idx\n                    correct += ((predicted == targets) * mask).sum().item()\n                    total += mask.sum().item()\n            \n            avg_train_loss = train_loss / len(data['train_loader'])\n            avg_val_loss = val_loss / len(data['dev_loader'])\n            val_acc = correct / total\n            \n            wandb.log({\n                \"epoch\": epoch,\n                \"train_loss\": avg_train_loss,\n                \"val_loss\": avg_val_loss,\n                \"val_acc\": val_acc\n            })\n            \n            # Save best model\n            if avg_val_loss < best_val_loss:\n                best_val_loss = avg_val_loss\n                torch.save(model.state_dict(), \"best_model.pth\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n\n# Sweep configuration\nsweep_config = {\n    'method': 'bayes',\n    'metric': {'name': 'val_loss', 'goal': 'minimize'},\n    'parameters': {\n        'embed_dim': {'values': [64, 128, 256]},\n        'hidden_size': {'values': [128, 256, 512]},\n        'enc_layers': {'values': [1, 2]},\n        'dec_layers': {'values': [1, 2]},\n        'cell_type': {'values': ['lstm', 'gru', 'rnn']},\n        'dropout': {'values': [0.0, 0.2, 0.3]},\n        'learning_rate': {'values': [0.001, 0.0005]},\n        'teacher_forcing': {'values': [0.5, 0.7]},\n        'epochs': {'value': 10}\n    }\n}\n\n# Initialize wandb and run sweep\nwandb.login(key =secret_value_0 )\nsweep_id = wandb.sweep(sweep_config, project=\"DA6401_assignment3\")\nwandb.agent(sweep_id, train)\n\n# Test function (to run after training)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def test_model(model, test_loader, trg_vocab):\n    model.eval()\n    correct = 0\n    total = 0\n    pad_idx = trg_vocab['<pad>']\n    \n    with torch.no_grad():\n        for batch in test_loader:\n            src = batch['source'].to(device)\n            trg = batch['target'].to(device)\n            \n            # Greedy decoding\n            outputs = model(src, trg, teacher_forcing_ratio=0)\n            outputs = outputs[:, 1:].reshape(-1, outputs.size(-1))\n            targets = batch['target_output'].to(device).reshape(-1)\n            \n            _, predicted = torch.max(outputs, 1)\n            mask = targets != pad_idx\n            correct += ((predicted == targets) * mask).sum().item()\n            total += mask.sum().item()\n    \n    return correct / total\n\n# Load best model and test\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nbest_model = Seq2Seq(\n    len(data['src_vocab']),\n    len(data['trg_vocab']),\n    embed_dim=256,  # Replace with best params from sweep\n    hidden_size=512\n).to(device)\nbest_model.load_state_dict(torch.load(\"best_model.pth\"))\ntest_acc = test_model(best_model, data['test_loader'], data['trg_vocab'])\nprint(f\"Test Accuracy: {test_acc:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# data =  prepare_dakshina_data(base_dir = \"/kaggle/input/dakshina/dakshina_dataset_v1.0\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}